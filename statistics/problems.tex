% Copyright (c) 2013â€“2014, authors of "Core Econometrics;" a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts. A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\chapter{Problems}

\begin{hw}
  Write an R function that calculates the maximum likelihood
  estimator of $\alpha$ and $\beta$ for the gamma$(\alpha,\beta)$
  distribution. Maximize the likelihood function numerically even if
  you are able to analytically derive the MLE. You may find the R
  functions \texttt{optim} and \texttt{dgamma} helpful. You should
  pay attention to the initial values of the numerical optimization
  procedure, and may want to use the method of moments to derive
  sensible initial values.
\end{hw}

\begin{hw}
  We often want to understand the properties of a statistical
  estimator that has too complicated of a distribution to calculate
  directly. Or we might know that the distribution of a statistical
  estimator is approximately equal to particular formula, but don't
  know how accurate the approximation will be in any application. For
  either situation, it can be useful to use a computer to simulate the
  estimator under different assumptions.

  It can be shown (i.e. \citet[p. 483]{CB02}) that if $X_1,\dots,X_n$
  is an i.i.d. sample with distribution and density $F$ and $f$
  respectively, then the sample median of $X_1,\dots,X_n$ is
  approximately (i.e. this holds at $n = \infty$) distributed $\N(\theta,
  (4 n f^2(\theta))^{-1})$, where $\theta$ is the population median.
  \begin{enumerate}
  \item Simulate 1000 samples of size 10 with $X \sim N(1,2)$ and plot
    a histogram of the sample median. Also plot the density of the
    limiting normal distribution on the same graph. How well does the
    approximation match the simulated density? Hint: you will find it
    easier if you use the R function \texttt{replicate}.
  \item Repeat the previous question with $n=100$.
  \item Repeat the first question with different distribution
    functions. What features of the distribution function affect the
    quality of the approximation?
  \end{enumerate}
\end{hw}

\begin{hw}
  Suppose that $X_1,\dots,X_n \sim i.i.d. N(\mu, \sigma^2)$. Is
  the sample median consistent for $\mu$? Is it asymptotically
  normal? Do these answers require the $X_i$ to be Normal?
\end{hw}

\begin{hw}
  Suppose that $X_1,\dots,X_n$ are distributed uniform$(0,b)$.
  Derive the LRT for the null hypothesis $b \geq b_0$ against the
  alternative $b < b_0$ and also for the null hypothesis $b \leq b_0$
  against $b > b_0$. Please discuss and compare the tests.
\end{hw}

\begin{hw}
  Suppose that $X_1,\dots,X_n$ are i.i.d. uniform($a$,$b$).
  Derive the LRT of the null hypothesis $\E X_i = 0$ against the
  two-sided alternative $\E X_i \neq 0$.
\end{hw}

\begin{hw}
  Let $X = (X_1,\dots,X_n)$ be a random sample and let $\theta$ be
  some parameter of interest. For each $\theta_0$, let $A(\theta_0)$
  be the acceptance region of a level $\alpha$ test of the null
  hypothesis that $\theta = \theta_0$. For each sample $x$, define a
  set $C(x)$ in the parameter space by
  \begin{equation}
     C(x) = \{ \theta_0 : x \in A(\theta_0) \}.
  \end{equation}
  Prove that the random set $C(X)$ is a $1-\alpha$ confidence set for the
  parameter $\theta$.
\end{hw}

\begin{hw}
  Suppose that $X_1,...,X_n \sim$ i.i.d. uniform($a$,$b$).
  \begin{enumerate}
  \item Derive the MLE of $\E X_i$ and prove that it is consistent.
  \item Please find the asymptotic distribution of the MLE of $\E
    X_i$. You will need to rescale the estimator to find an
    asymptotic distribution. Two hints: it is not asymptotically
    normal; and you may need to use the result $(1 + \tfrac{1}{n})^n \to
    e$ as $n \to \infty$ (``may'' meaning that my solution uses that result).
  \end{enumerate}
\end{hw}

\begin{hw}
  Suppose $X_1,...,X_n \sim$ uniform$(-\theta, \theta)$. Find the
  method-of-moments estimator of $\theta$ based on
  \begin{equation*}
    n^{-1} \sum_{i=1}^n X_i^2.
  \end{equation*}
  Is it consistent? Asymptotically normal?
\end{hw}

\begin{hw}
  Let $X_1,...,X_n \sim N(\theta, \theta)$. Derive the MLE of
  $\theta$ and show that it is asymptotically normal.
\end{hw}

\begin{hw}
  Suppose that $X_1,...,X_n$ are an i.i.d. sample from the density
  $f(x) = 1/\theta$, $0 \leq x \leq \theta$. Prove that $\max_i X_i$
  is consistent for $\theta$.
\end{hw}

\begin{hw}
  Suppose that $X_1,...,X_n \sim$ i.i.d. uniform($a$,$b$).
  \begin{enumerate}
  \item Show that $(\min_i X_i, \max_i X_i)$ is the maximum likelihood
    estimator of $(a,b)$.
  \item Prove that the MLE is consistent.
  \item Please find the asymptotic distribution of the MLE. You will
    need to rescale the estimator to find an asymptotic distribution.
    Two hints: it is not asymptotically normal; and you may need to
    use the result $(1 + \tfrac{1}{n})^n \to e$ as $n \to \infty$.
  \item Use your answer to the previous question to construct a
    two-sided 90\% confidence interval for $b$.
  \item When we derived the asymptotic distribution earlier, we used
    only some aspects of the assumption that $X_i \sim$
    uniform($a$,$b$). Can you show that $\max_i X_i$ and $\min_i X_i$
    have the same asymptotic distribution that we derived above under
    weaker assumptions?
  \end{enumerate}
\end{hw}

\begin{hw}
  Let $\{y_t\}$ be an iid $N(0,\sigma^2)$ sequence. Define $S_T =
  (T-1)^{-1} \sum_{t=1}^T (y_t - \bar y)^2$.
  \begin{enumerate}
  \item Prove that $\sqrt{n} (S_T - \sigma^2) \to N(0,2\sigma^4)$ in
    distribution.
  \item Calculate the asymptotic distribution of $\log S_T$.
  \item Do your results depend on the normality of $y_t$?
  \item Calculate the 90th and 95th percentile for $S_T$ with
    arbitrary values of $\sigma^2$ using both of these asymptotic
    distributions.
  \item Use each of these results to derive a test of the null
    hypothesis $\sigma^2 = \sigma_0^2$ against the null $\sigma^2 >
    \sigma_0^2$, where $\sigma_0^2$ is a known but arbitrary value.
    Your answer should give two formulas for the test's critical
    value---each one depends on $\sigma_0^2$ and $\alpha$ (the nominal
    size of the test) and you should have a separate answer for each
    asymptotic approximation.
  \item Let $c_1$ and $c_2$ denote the 90th percentiles that you
    calculated in question ?. Simulate 1000 i.i.d. standard normal
    samples with $n = 50$ and calculate the probability that $S_T$ is
    less than each of these percentiles.
  \item Repeat the previous question for the 95th percentiles.
  \item Plot a histogram of your 1000 simulated $S_T$ along with each
    approximate density for $S_T$. What do these results tell you
    about the quality of the approximations?
  \item You can also prove that $(T-1) S_T$ has a chi-square
    distribution with $T-1$ degrees of freedom in finite samples.
    Calculate the 90th and 95th percentiles of $S_T$ using this
    chi-square distribution and repeat the previous two simulations.
    How do these simulations compare to the previous simulations?
  \item Repeat the previous three questions using a skewed
    distribution and a heavy-tailed distribution (changing the
    approximation as necessary). How do the results change? How do
    they change if you use different values of $n$?
  \item What do these simulations tell you about using these
    approximations for testing. Focus on the usual confidence levels
    (i.e. 10\%, 5\%, and 1\% tests).
  \end{enumerate}
\end{hw}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../core_econometrics"
%%% End: 
