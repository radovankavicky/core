% Copyright (c) 2013, authors of "Core Econometrics;" a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\chapter{Asymptotic properties of estimators in general}

\section{Consistency of point estimators}

\begin{itemize}[leftmargin=0pt]

\item Consistency is an asymptotic version of unbiasedness
  \begin{defn}
    An estimator $\thetah$ is a \emph{consistent} estimator of the
    parameter $\theta$ if $\thetah \to^p \theta$ for any value of $\theta$.
  \end{defn}

  Obviously, if $\E \thetah \to \theta$ and $\var(\thetah) \to 0$ then $\thetah$ is
  consistent.

\item It is straightforward to show that Method of Moments estimators
  are consistent as well.  Suppose that
  \begin{enumerate}
  \item $X_1,...,X_n$ are independent $p$ vectors
  \item $(\E X_i,...,\E X_i^k) = g(\theta_1,...,\theta_k)$ and $g^{-1}$ is
    continuous
  \item $(1/n) \sum_{i=1}^n X_i^p$ obeys an LLN for $p = 1,...,k$,
  \end{enumerate}
  then
  \begin{equation*}
    g^{-1}\Big( (1/n) \sum_{i=1}^n X_i,..., (1/n) \sum_{i=1}^n X_i^k \Big)
    \to^p (\theta_1,...,\theta_k),
  \end{equation*}
  so the Method of Moments estimator is consistent.

\item It is less straightforward to show this, but MLEs are typically
  consistent as well under technical regularity conditions on the
  distributions of the underlying random variables.  This is one
  justification for using MLE.

\end{itemize}

\section{Hypothesis testing and interval estimation in general}

\begin{itemize}[leftmargin=0pt]

\item Let $\{T_n\}$ be a sequence of test statistics for $\theta \in \theta_0$
  against $\theta \in \theta_A$.  The sequence of tests has asymptotic size $\alpha$ if
  \begin{equation*}
    \lim_{n \to \infty} \sup_{\theta \in \theta_0} \Pr_\theta[T_n \text{ rejects}] = \alpha
  \end{equation*}
  It would be great to discuss local alternatives here.

\item Let $\{[L_n, U_n\}$ be a sequence of interval estimators for a
  parameter $\theta$.  The asymptotic confidence level for this sequence of
  statistics is
  \begin{equation*}
    \lim_{n \to \infty} \inf_\theta \Pr_{\theta}[\theta \in [L_n, U_n]].
  \end{equation*}
  It would be great to discuss uniformity here.

\end{itemize}

\section{Specific methods of producing test statistics}

\begin{itemize}[leftmargin=0pt]

\item There are a few key principles that can be used to produce test
  statistics in very general conditions.

\item The Wald tests is built on the CLT explicitly.  Suppose we want
  to test the null $\theta = \theta_0$ and we have an asymptotically normal
  estimator $\thetah_n$, so $\sqrt{n} (\thetah_n - \theta) \to^d N(0,\Sigma)$ for all $\theta$
  and that $\Sigmah$ is a consistent estimator of $\Sigma$.  Then if the null
  hypothesis is $\theta = \theta_0$, we know that
  \begin{equation*}
    n (\thetah_n - \theta_0)' \Sigmah^{-1} (\thetah_n - \theta_0) \to^d \chi^2_p
  \end{equation*}
  where $p$ is the dimension of $\theta_0$.

\item Under appropriate regularity conditions, the Likelihood Ratio
  Test is asymptotically chi-square as well.  So is a test based on
  the first order conditions, which is called the \emph{score} or
  \emph{LM} test.

\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../core_econometrics"
%%% End: