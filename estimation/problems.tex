% Copyright © 2013, authors of the "Econometrics Core" textbook; a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\part*{Problem set, point estimation}%
\addcontentsline{toc}{part}{Problem set, point estimation}

\begin{enumerate}

\item Write an R function that calculates the maximum likelihood
  estimator of $α$ and $β$ for the gamma$(α,β)$ distribution. Maximize
  the likelihood function numerically even if you are able to
  analytically derive the MLE.  You may find the R functions
  \texttt{optim} and \texttt{dgamma} helpful.  You should pay
  attention to the initial values of the numerical optimization
  procedure, and may want to use the method of moments to derive
  sensible initial values.

\item We often want to understand the properties of a statistical
  estimator that has too complicated of a distribution to calculate
  directly.  Or we might know that the distribution of a statistical
  estimator is approximately equal to particular formula, but don't
  know how accurate the approximation will be in any application.  For
  either situation, it can be useful to use a computer to simulate the
  estimator under different assumptions.

  It can be shown (i.e. \citet[p. 483]{CB02}) that if
  $X₁,…,X_n$ is an i.i.d. sample with distribution and density $F$
  and $f$ respectively, then the sample median of $X₁,…,X_n$ is
  approximately (i.e. this holds at $n = ∞$) distributed $\N(θ, (4 n
  f²(θ))^{-1})$, where $θ$ is the population
  median.
  \begin{enumerate}
  \item Simulate 1000 samples of size 10 with $X ∼ N(1,2)$ and plot
    a histogram of the sample median.  Also plot the density of the
    limiting normal distribution on the same graph.  How well does the
    approximation match the simulated density?  Hint: you will find it
    easier if you use the R function \texttt{replicate}.
  \item Repeat the previous question with $n=100$.
  \item Repeat the first question with different distribution
    functions.  What features of the distribution function affect the
    quality of the approximation?
  \end{enumerate}

\item Suppose that $X₁,…,X_n ∼ i.i.d. N(μ, σ²)$.  Is
  the sample median consistent for $μ$?  Is it asymptotically
  normal?  Do these answers require the $X_i$ to be Normal?

\item Let $\{e_t\}$ be a sequence of i.i.d. $(0,1)$ random variables
  and let $X_t = e_t + 0.5\, e_{t-1}$.  Such a process is called a
  Moving Average of order 1, abbreviated as MA(1).  What is the
  probability limit of $n^{-1} ∑_{t=1}ⁿ X_t$ as $n → ∞$?

\item Suppose that $Z$ is a random variable with mean $μ$ and variance
  $σ$ and let $e₁,e₂,…$ be a sequence of i.i.d. random variables with
  mean zero and variance 1 that are independent of $Z$.  Show that the
  sequence $X_i = Z + e_i$ obeys the following weak law of large
  numbers: as $n → ∞$, $n^{-1} ∑_{i=1}ⁿ ( X_i - \E(X_i ∣ Z) ) → 0$ in
  probability.  Note that $X₁,X₂,…$ is \emph{not} an i.i.d.\ sequence,
  but is an example of an \emph{exchangeable} sequence of random
  variables.

\item Suppose that $X_n →^p X$ and that $g$ is a continuous function.
  Prove that $g(X_n) →^p g(X)$.

\item Let $X₁,…,X_n ∼ N(θ, θ)$.  Derive the MLE of $θ$ and show that
  it is asymptotically normal.

\item Suppose that $X₁,…,X_n$ are an i.i.d. sample from the density
  $f(x) = 1/θ$, $0 ≤ x ≤ θ$.  Prove that $\max_i X_i$ is consistent
  for $θ$.

\end{enumerate}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../../estimation"
%%% End: 
