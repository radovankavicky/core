% Copyright © 2013, authors of the "Econometrics Core" textbook; a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\part*{Introduction to hypothesis testing}%
\addcontentsline{toc}{part}{Introduction to hypothesis testing}

\begin{itemize}
\item Motivation
\begin{itemize}
\item there are many settings where we care what the unknown
       coefficients are.
\begin{itemize}
\item forecasting
\item setting policy
\end{itemize}
\item there are plenty of other settings where we don't really care what
       the coefficients are, but just want to know whether the
       coefficient is above some threshold
\end{itemize}
\item Example: have a basic relationship: $wage_t = β₀ + β₁
     × education_t + \ep_t$
\begin{itemize}
\item may want to know whether $β₁$ is positive
\item may want to know whether $β₁$ is above some threshold that
       makes funding a program worthwhile
\item probably don't care about whether or not $β₁$ is exactly
       2.95 vs 2.97 -- they probably mean exactly the same thing as far
       as your decision is concerned.  But $-0.01$ vs 0.01 probably don't
       mean exactly the same thing as far as decisions are concerned
\item For (most) estimation, though, we would treat mismeasuring the
       true parameter by 0.02 the same, whether the true value was 2.95
       or $-0.01$
\end{itemize}
\end{itemize}

\section{Basic setup for testing}

\subsection{Definition of test statistic}

\begin{itemize}
\item Suppose that you have two different hypotheses about the
       unknown parameters of the DGP
\begin{description}
\item[null] $θ ∈ Θ₀$
\begin{itemize}
\item the null hypothesis is what we would believe about $θ$ if we
           had no data about the problem
\end{itemize}
\item[alternative] $θ ∈ Θ_a$
\begin{itemize}
\item the alternaive hypothesis is a candidate belief that might be true.
\item but we need \textbf{strong} evidence before we believe it
\end{itemize}
\end{description}
\item A \emph{test statistc} is a statistic that specifies the following:
\begin{enumerate}
\item For which samples do we make the decision to accept $θ_a$
          (our alternative) as true
\item For which samples do we \textbf{not} make that decision, and instead
          act as though $θ₀$ were true.
\end{enumerate}
\end{itemize}

\subsection{Example of a test statistic}

\begin{itemize}
\item Suppose $X₁,...,X_n ∼ iid N(μ,1)$ and we have the hypotheses:
\begin{description}
\item[null] $μ = 0$
\item[alt] $μ = 1$
\end{description}
\item we can use the standard one-sided test statistic:
\begin{description}
\item[reject 0] if $\sqrt{n} (\Xb - μ₀) / σ = \sqrt{n}
                     \Xb ≥ 1.64$
\item[accept 0] if $\sqrt{n} \Xb < 1.64$
\end{description}
\item tells us that we reject null for any sample that gives us a mean
       greater than $1.64 / \sqrt{n}$ and do not reject for other
       samples
\end{itemize}

\subsection{Error types and probabilities}

\begin{itemize}
\item Test statistics can't be foolproof.
\begin{itemize}
\item Even if $μ = 0$, we'll see some samples that have a sample
         mean greater than $1.64 / \sqrt{n}$
\item If $μ = 1$, we'll also see samples with a small mean
\item The key aspect of statistical testing is that we can calculate
         the probabilities of making different sorts of errors, and
         design procedures that make errors that we're comfortable with.
\end{itemize}
\item Possible outcomes:
\begin{itemize}
\item null is true, test statistic does not reject
\begin{itemize}
\item great!
\end{itemize}
\item null is true, test statistic does reject
\begin{itemize}
\item problem
\end{itemize}
\item null is false, test statistic does not reject
\begin{itemize}
\item problem
\end{itemize}
\item null is false, test statistic rejects
\begin{itemize}
\item great!
\end{itemize}
\end{itemize}
\item key philosophy behind testing:
\begin{itemize}
\item we set up the problems so that the null is what we'd do
         without data.
\item consequently, if the null is false, but the test statistic
         does not reject, it's not so bad
\item \textbf{but} if the null is true and we reject it, that is bad.
\begin{itemize}
\item we should need more evidence to change our behaviour than we
           would need to keep doing the same thing we were.
\end{itemize}
\item advantages of this approach:
\begin{itemize}
\item simplifies the mathematics considerably
\item intuitively appealing.
\item matches up with actual practice in ``academic'' scientific experiments
\end{itemize}
\end{itemize}
\item terminology
\begin{itemize}
\item type one error: reject when you shouldn't
\item type two error: don't reject when you should
\item power: probability that the test rejects (usually will depend
         on the value of the true parameter).
\begin{itemize}
\item formally, let $β(θ) = \Pr_θ[reject]$.  $β(θ)$ is the power function.
\end{itemize}
\item size: probability that the test rejects if the null hypothesis is true;
\begin{itemize}
\item i.e. probability of type I error
\item a test is \emph{size} $α$ if $\sup_{θ ∈ Θ₀} β(θ) = α$
\item a test is \emph{level} $α$ if $\sup_{θ ∈ Θ₀} β(θ) ≤ α$
\item \textbf{size} is what we care most about.  We want to set the size
\end{itemize}
\item valid: a test that has correct size -- ie rejects if the null
         is true at the percentages we want
\item unbiased: a test is unbiased if $\inf_{θ ∈ Θ_A} β(θ) ≥ α$
\end{itemize}
\end{itemize}

\subsection{Motivating example}

\begin{itemize}
\item sometimes we can monkey with a statistic to get a test
\item think back to normal distribution with $H₀: μ = 0$ vs
       $H_a: μ = 1$ and we want to test at 5\%
\begin{itemize}
\item statistic was $\sqrt{n} \Xb$.
\item if $μ = 0$, then we know that $\sqrt{n} \Xb$ is standard normal.
\item $\Xb > 0$ is evidence against the null, so let's try to
         find a threshold that preserves size
\begin{itemize}
\item find $c$ such that $\Pr[\sqrt{n} \Xb ≥ c] = 0.05$
  \begin{align*}
    \Pr[\sqrt{n} \Xb ≥ c] &= 1 - \Pr[\sqrt{n} \Xb < c] \\
    &= 1 - \Pr[\sqrt{n} \Xb ≤ c] \text{ (continuity)} \\
    &= 1 - Φ(c)
  \end{align*}
  so, $Φ(c) = 0.95$ and $c = Φ^{-1}(0.95) \approx 1.64$
\end{itemize}
\item So the probability that $\sqrt{n} \Xb ≥ 1.64 = 0.05$
\item so, the probability of rejecting if the null hypothesis is
         true is 0.05.
\begin{itemize}
\item the size of the test is 0.05
\item if we want to change the size of the test, all we have to
           do is change 1.64 to a different number.
\end{itemize}
\end{itemize}
\item power
\begin{itemize}
\item knowing the distribution under the null gives us size
\item to find out the power, we want to know the distribution under
         the alternative
\begin{itemize}
\item if $μ = 1$ then $\sqrt{n}(\Xb - 1)$ is standard normal.
\item $β(1) = P[\sqrt{n} \Xb ≥ 1.64] = P[\sqrt{n}(\bar
           X - 1) ≥ 1.64 - \sqrt{n}] = 1 - Φ(1.64 - \sqrt{n}) → 1$
\end{itemize}
\end{itemize}
\end{itemize}

\subsection{p-values}

\begin{itemize}
\item Say you're working, do a test at 5\% and want to show your advisor
\item maybe your advisor is more or less tolerant of type 1 error
\item so you test at 10\%, 9.9\%, 9.8\%, etc and record rejections and
  acceptances
\item but, you could summarize that by looking at the smallest
  critical value for which you would reject
\item this critical value is the p-value
\end{itemize}

\section{Relationship between hypothesis testing and confidence
  intervals}

\begin{itemize}

\item There is a fundamental relationship between testing hypotheses
  and constrcting confidence intervals.  Given any hypothesis test, we
  can construct a corresponding confidence interval as
  follows \citep[As described in][Section 9.2]{CaB_2001}:

  For each $θ₀$, let $A(θ₀)$ be the acceptance region of a level $α$
  test of $H₀: θ = θ₀$.  For each sample $x$, define a set $C(x)$ in
  the parameter space by \[C(x) = \{θ₀: x ∈ A(θ₀)\}\].  Then the
  random set $C(X)$ is a $1-α$ confidence set.\sidenote{You should
    prove this on your own for homework.  The proof follows
    immediately from the definition of each set, but it can take some
    thought and work to realize it.  Start by writing out the
    definition of a $1-α$ confidence set and then verify by set
    relationships that $C(X)$ satistifies the definition.}

\item Here's an example using this result:
  \begin{itemize}
  \item suppose $X₁,…,X_n ∼ N(μ,σ²)$ and we want to construct a
    two-sided $1-α$ confidence interval for $μ$.
    \begin{itemize}
    \item $σ²$ is known
    \end{itemize}
  \item start by getting the family of tests:
    \begin{itemize}
    \item test of $H₀: μ = μ₀$ vs $μ ≠ μ₀$ is given by:
      \begin{description}
      \item[reject] if $μ₀ > \Xb + z_{α/2} σ / \sqrt{n}$ or $μ₀ < \Xb
        - z_{α/2} σ / \sqrt{n}$.
      \item[accept] otherwise
      \end{description}
    \item gives $A(μ₀) = \{x :\Xb - z_{α/2} σ / \sqrt{n} ≤ μ₀ ≤ \Xb +
      z_{α/2} σ / \sqrt{n}\}$
    \item then $C(x) = \{μ :\Xb - z_{α/2} σ / \sqrt{n} ≤ μ ≤ \Xb +
      z_{α/2} σ / \sqrt{n}\}$
      \begin{itemize}
      \item we're changing two things
        \begin{description}
        \item[.] the set $A(μ₀)$ has samples as its elements
        \item[.] the set $C(x)$ has parameter values as its elements
        \item[.] $A(μ₀)$ is different for different parameter values
        \item[.] $C(x)$ is different for different samples
        \end{description}
      \end{itemize}
    \end{itemize}
  \end{itemize}
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../inference"
%%% End:
