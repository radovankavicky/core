% Copyright (c) 2013, authors of "Core Econometrics;" a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\chapter{Estimating causal relationships and dealing with endogeneity}

\section{Relaxing the complete exogeneity assumption}

\begin{itemize}[leftmargin=0pt]

\item The assumption that all of the regressors are exogenous is
  usually unjustified. Suppose that we have a DGP
  \begin{equation*}
    y_i = \beta_0 + \beta_1 \text{education}_i
    + \beta_2 \text{ability}_i + \varepsilon_i
  \end{equation*}
  where education is observed but ability is not, and they're
  potentially correlated. We want to estimate $\beta_1$. Here we
  assume that
  \begin{equation*}
    \E(\vep_i \mid \text{education}_i, \text{ability}_i) = 0 \ a.s.
  \end{equation*}
  The regression of $y_i$ on $\text{education}_i$ would then be biased
  for $\beta_1$.

  A common approach is to add variables related to ability to the
  regression and then estimate the model
  \begin{equation*}
    y_i = \beta_0 + \beta_1 \text{education}_i
    + \gamma'\text{controls}_i
    + \underbrace{\beta_2 \text{ability}_i - 
                  \gamma'\text{controls}_i + \varepsilon_i}_{u_i}
  \end{equation*}
  where $u_t$ is the unobserved error in the regression of $y_i$ on
  education and the additional controls. Obviously, if
  \begin{equation*}
    \gamma'\text{controls}_i = \beta_2 \text{ability}_i
  \end{equation*}
  almost surely for a particular value of $\gamma$, there are no
  problems. But that is very unlikely.

  A more likely situation is that the expected value of
  $\text{ability}_i$ is independent of $\text{education}_i$, once we
  condition on the controls. Mathematically, this means that
  \begin{align*}
    \E(\text{ability}_i \mid \text{education}_i, \text{controls}_i)
    &= \E(\text{ability}_i \mid \text{controls}_i) && a.s. \\
    &= \alpha_0 + \alpha_1'\text{controls}_i && a.s.
  \end{align*}
  where we impose linearity in the second equation, but that the last
  conditional expectation is not zero.

  Under this setup, we can work out the parameter values identified by
  OLS. Assume the controls are univariate (for simplicity) and that
  $\beta_0 = 0$, so OLS identifies the parameters
  \newcommand{\ab}{\text{ab}}
  \newcommand{\ed}{\text{ed}}
  \newcommand{\co}{\text{c}}
  \begin{align*}
    \begin{pmatrix}
      \beta_1^* \\ \gamma^*
    \end{pmatrix} &=
    \begin{pmatrix}
      \E \ed_i^2 & \E \ed_i \co_i \\ \E \ed_i \co_i & \E \co_i^2
    \end{pmatrix}^{-1}
    \begin{pmatrix}
      \E \ed_i y_i \\ \E \co_i y_i
    \end{pmatrix}
    \\ &= \frac{1}{\E \ed_i^2 \E \co_i^2 - (\E \ed_i \co_i)^2}
    \begin{pmatrix}
      \E \co_i^2 & -\E \ed_i \co_i \\ -\E \ed_i \co_i & \E \ed_i^2
    \end{pmatrix}
    \begin{pmatrix}
      \E \ed_i (\beta_1 \ed_i + \beta_2 \ab_i + \vep_i) \\
      \E \co_i (\beta_1 \ed_i + \beta_2 \ab_i + \vep_i)
    \end{pmatrix} \\
    &= \frac{1}{\E \ed_i^2 \E \co_i^2 - (\E \ed_i \co_i)^2}
    \begin{pmatrix}
      \E \co_i^2 & -\E \ed_i \co_i \\ -\E \ed_i \co_i & \E \ed_i^2
    \end{pmatrix}
    \begin{pmatrix}
      \beta_1 \E \ed_i^2 + \beta_2 \E \ed_i \ab_i \\
      \beta_1 \E \ed_i \co_i + \beta_2 \E \co_i \ab_i
    \end{pmatrix}
  \end{align*}
  where we have used the assumption that $\ed_i$ and $\vep_i$ are
  uncorrelated and an implicit assumption that $\co_i$ and $\vep_i$
  are uncorrelated. ($\vep_i$ is being treated here as irreducible
  error; otherwise include the part correlated with $\co_i$ in with
  $\ab_i$.)

  We can then see that
  \begin{equation*}
    \beta_i^* = \beta_1 + \beta_2 
    \frac{\E \co_i^2 \E \ed_i \ab_i - \E\ed_i \co_i \E \co_i \ab_i}%
    {\E \ed_i^2 \E \co_i^2 - (\E \ed_i \co_i)^2},
  \end{equation*}
  so $\beta_i^* = \beta_1$ only if
  \begin{align*}
    0
    &= \E \ed_i \ab_i - \E\ed_i \co_i \E \co_i \ab_i / \E \co_i^2 \\
    &= \E\big( \ab_i \big(\ed_i - \co_i (\E \co_i^2)^{-1}\E(\co_i
    \ed_i) \big) \big).
  \end{align*}
  Now, notice that
  \begin{equation*}
    \ed_i - \co_i (\E \co_i^2)^{-1}\E(\co_i \ed_i)
  \end{equation*}
  is the component of $\ed_i$ orthogonal to $\co_i$ and so is
  uncorrelated with $\ab_i$, ensuring that $\beta_1^* = \beta_1$
  (elaborate).

\item This argument means that OLS is able to estimate $\beta_1$ even
  though the other controls are necessarily endogenous.

\item This would be a good place to explain how the same issue arises
  in true experiments.

\end{itemize}

\section{Using too many regressors}

This would be a good place to discuss having regressors that interrupt
the causal effect. An example: suppose that you want to know the
effect that taking a college test prep class has on college admissions
(at the individual level). One might imagine including SAT scores as a
regressor, if they were available. But the main mechanism that we'd
expect this sort of class to affect college admissions is through test
scores, so ``controling for'' test scores probably doesn't make sense.

\section{Instrumental variable estimators}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../core_econometrics"
%%% End: 
