% Copyright (c) 2013, authors of "Core Econometrics;" a
% complete list of authors is available in the file AUTHORS.tex.

% Permission is granted to copy, distribute and/or modify this
% document under the terms of the GNU Free Documentation License,
% Version 1.3 or any later version published by the Free Software
% Foundation; with no Invariant Sections, no Front-Cover Texts, and no
% Back-Cover Texts.  A copy of the license is included in the file
% LICENSE.tex and is also available online at
% <http://www.gnu.org/copyleft/fdl.html>.

\chapter{Dealing with endogeneity}

\section{Problems in modeling}

\paragraph{Omitted variables}
\begin{itemize}
\item We've assumed so far that $Y = X\beta + \vep$ with $\E(\vep \mid X) = 0$.
\item Suppose that the true model is
  \[Y = X\beta + Z\alpha + \vep\] with $\E(\vep \mid X, Z) = 0$
\begin{itemize}
\item but you regress $Y$ on $X$ (and not $Z$)
\item e.g. $Y$ is income, $X$ is education and experience, and
          $Z$ is some numeric measure of ability.
\item maybe $Z$ is unobserved
\item maybe there are other reasons you omit it (ignorance, possibly)
\end{itemize}
\item Is the OLS estimator consistent for $\beta$?
\end{itemize}

\paragraph{mathematical consequences}
\begin{itemize}
\item Rewrite the true relationship
  \[ Y = X\beta + (Z\alpha + \vep) \equiv X\beta + u \]
\item we know that (under reasonable assumptions ensuring LLNs)
  \begin{align*}
    \betah - \beta
    &= (n^{-1} X'X)^{-1}(n^{-1} X'u) \\
    &\to^p (\E(x_{i}x_{i}'))^{-1} \lim n^{-1} \sum_{i=1}^{n} x_{i} \E(u_{i} \mid X)
  \end{align*}
\item \textbf{But} we can't assume that $\E(u_i \mid X) = 0$ (a.s.)
\begin{itemize}
\item $\E(u_{i} \mid X) = \E(\alpha z_{i} \mid X) + \E(\vep_{i} \mid X)$
\begin{itemize}
\item The second term is zero since (by the L.I.E.)
  \[\E(\vep_{i} \mid X) = \E(\E(\vep_{i}\mid X, Z) \mid X) = 0\]
\item The first term is zero only if
\begin{itemize}
\item $\alpha = 0$
\item $\E(x_{i} z_{i}) = 0$
\end{itemize}
\end{itemize}
\end{itemize}
\item Think back to our example
\begin{itemize}
\item $\E(ability \mid education, experience)$ is probably not zero
\item $\alpha = 0$ only if ability doesn't affect income, after
           taking education and experience into account
\item both are probably not zero
\item OLS on just $X$ is going to give you a biased and
           inconsistent estimate.
\end{itemize}
\end{itemize}

\paragraph{remedies}

\paragraph{include the variable!}
\begin{itemize}
\item If you observe $Z$, it's usually a good idea to include it
          in the regression.
\begin{itemize}
\item a caveat with small sample sizes: when $\alpha$ is close
            to zero, this can increase the variance of your estimator
            enough that including the variable is a bad idea
\item when $\alpha$ is close to zero, the bias is small too.
\end{itemize}
\item we'll discuss ways to determine whether or not you should
          include a variable soon
\end{itemize}

\paragraph{proxies -- see \citet[Section 12.5]{Gre12}}
\begin{itemize}
\item What if you can't include the variable?
\begin{itemize}
\item ability might be impossible to directly observe, for
            example.
\end{itemize}
\item Suppose you included a different variable that is a measure
          of the missing variable
\begin{itemize}
\item A test score instead of ability
\item Call that variable $W$; moreover, suppose that
            \[W = \gamma_0 + Z \gamma_1 + \delta\]
            so $W$ is unrelated to the $X$ variables
\end{itemize}
\item What happens if you regress $Y$ on $X$ and $W$?
\end{itemize}
\begin{itemize}

\item mathematical representation of proxies
\begin{itemize}
\item We can solve for $Z$ in the previous relationship:
  \[ Z = (W - \gamma_0 - \delta ) / \gamma_1 \]
\item We can rewrite the true relationship as
  \begin{align*} 
    Y &= X\beta + Z\alpha + \vep \\
    &= \beta_0 + X\beta + (W - \gamma_0 - \delta) \alpha/\gamma_1 \\
    &= (\beta_0 - \gamma_0\alpha/\gamma_1) + X\beta + W \alpha/\gamma_1 + (\vep - \alpha/\gamma_1\delta)
  \end{align*}
\item If $\E(\delta \mid X, W) = 0$ (which may be reasonable), we
           can use OLS to get consistent estimates of
\begin{itemize}
\item $\beta-\gamma_0\alpha/\gamma_1$ (the new intercept)
\item $\beta$
\item $\alpha/\gamma_1$ (the slope on W)
\end{itemize}
\item In our setup, we only care about $\beta$, and we can
           estimate it consistently by OLS (and unbiased, too).
\item The same concept applies with more than one variable
\begin{itemize}
\item Note that $\alpha/\gamma_1$ is complicated
\item Will be more complicated with more variables
\item In particular, it can have a \textbf{different sign} than $\alpha$.
\end{itemize}
\end{itemize}
\end{itemize}

\paragraph{Inclusion of too many variables}
\begin{itemize}
\item We saw this earlier in the lecture
\item If we include variables that have population coefficients equal
        to zero, the variance of our estimator increases and the model
        is less accurate
\item The coefficients are still unbiased, though.
\end{itemize}
